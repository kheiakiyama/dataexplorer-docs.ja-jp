---
title: 継続的なデータのエクスポート-Azure データエクスプローラー |Microsoft Docs
description: この記事では、Azure データエクスプローラーでの継続的なデータエクスポートについて説明します。
services: data-explorer
author: orspod
ms.author: orspodek
ms.reviewer: yifats
ms.service: data-explorer
ms.topic: reference
ms.date: 08/03/2020
ms.openlocfilehash: 7f9465df4847a24a4877c8b1cb637ba1d7542db3
ms.sourcegitcommit: 898f67b83ae8cf55e93ce172a6fd3473b7c1c094
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/21/2020
ms.locfileid: "92342537"
---
# <a name="continuous-data-export-overview"></a>継続的なデータエクスポートの概要

この記事では、定期的に実行されるクエリを使用して、Kusto から [外部テーブル](../external-table-commands.md) にデータを連続エクスポートする方法について説明します。 結果は、Azure Blob Storage、エクスポートされたデータのスキーマなどの変換先を定義する外部テーブルに格納されます。 このプロセスでは、すべてのレコードが "厳密に1回" エクスポートされることを保証しますが、 [例外](#exactly-once-export)もあります。 

連続したデータのエクスポートを有効にするには、 [外部テーブルを作成](../external-tables-azurestorage-azuredatalake.md#create-or-alter-external-table) し、外部テーブルを指す [連続エクスポート定義を作成](create-alter-continuous.md) します。 

> [!NOTE]
> 連続エクスポートのすべてのコマンドには、 [データベース管理者のアクセス許可](../access-control/role-based-authorization.md)が必要です。

## <a name="continuous-export-guidelines"></a>連続エクスポートのガイドライン

* **出力スキーマ**:
  * エクスポートクエリの出力スキーマは、エクスポート先の外部テーブルのスキーマと一致している必要があります。 
* **頻度**:
  * 連続エクスポートは、プロパティで構成された期間に従って実行され `intervalBetweenRuns` ます。 この間隔の推奨値は、許容される待ち時間に応じて、少なくとも数分です。 インジェスト率が高い場合、時間間隔は1分間に抑えることができます。
* **配布**:
  * 連続エクスポートでの既定のディストリビューションはで `per_node` 、すべてのノードが同時にエクスポートされます。 
  * この設定は、連続エクスポートの create コマンドのプロパティでオーバーライドできます。 分散を使用して `per_shard` 同時実行性を高めます。
    > [!NOTE]
    > このディストリビューションにより、ストレージアカウントの負荷が増加し、調整制限に達してしまう可能性があります。 
  * `single` `distributed` = `false` ディストリビューションを完全に無効にするには、(または) を使用します。 この設定により、連続エクスポートプロセスが大幅に遅くなり、連続エクスポートの各反復で作成されるファイルの数が影響を受ける可能性があります。 
* **ファイルの数**:
  * 連続エクスポートの各繰り返しでエクスポートされるファイルの数は、外部テーブルのパーティション分割方法によって異なります。 詳細については、「 [外部テーブルへのエクスポートコマンド](export-data-to-an-external-table.md#number-of-files)」を参照してください。 連続エクスポートの反復は、常に新しいファイルに書き込み、既存のファイルには追加されません。 その結果、エクスポートされたファイルの数も、連続エクスポートが実行される頻度によって決まります。 Frequency パラメーターが `intervalBetweenRuns` です。
* **場所**:
  * 最適なパフォーマンスを得るには、Azure データエクスプローラークラスターとストレージアカウントを同じ Azure リージョンに共存させる必要があります。
  * エクスポートされたデータ量が大きい場合は、ストレージの調整を回避するために、外部テーブルに対して複数のストレージアカウントを構成することをお勧めします。 「 [データをストレージにエクスポートする」を](export-data-to-storage.md#known-issues)参照してください。

## <a name="exactly-once-export"></a>厳密に1回のエクスポート

"厳密に1回" のエクスポートを保証するために、連続エクスポートでは [データベースカーソル](../databasecursor.md)を使用します。 [IngestionTime ポリシー](../ingestiontime-policy.md) は、エクスポートで "厳密に1回" 処理する必要があるクエリで参照されるすべてのテーブルで有効にする必要があります。 このポリシーは、新しく作成されたすべてのテーブルで既定で有効になっています。

"厳密に1回" のエクスポートの保証は、[エクスポートされた [アーティファクトの表示] コマンド](show-continuous-artifacts.md)で報告されたファイルに対してのみ実行されます。 連続エクスポートでは、各レコードが外部テーブルに1回だけ書き込まれることは保証されません。 エクスポートの開始後にエラーが発生し、一部のアイテムが既に外部テーブルに書き込まれていた場合は、外部テーブルに重複が含まれている可能性があります。 書き込み操作が完了前に中止された場合、外部テーブルに破損したファイルが含まれている可能性があります。 このような場合、アイテムは外部テーブルから削除されませんが、[エクスポートされた [アーティファクトの表示] コマンド](show-continuous-artifacts.md)では報告されません。 を使用してエクスポートされたファイルを使用する `show exported artifacts command` と、重複と破損は保証されません。

## <a name="export-to-fact-and-dimension-tables"></a>ファクトテーブルとディメンションテーブルへのエクスポート

既定では、エクスポートクエリで参照されるすべてのテーブルは、 [ファクトテーブル](../../concepts/fact-and-dimension-tables.md)と見なされます。 そのため、データベースカーソルにスコープが設定されています。 この構文では、スコープ (ファクト) であり、スコープが設定されていないテーブル (ディメンション) を明示的に宣言します。 `over`詳細については、 [create コマンド](create-alter-continuous.md)のパラメーターを参照してください。

エクスポートクエリには、前回のエクスポート実行以降に結合されたレコードのみが含まれます。 エクスポートクエリには、ディメンションテーブルのすべてのレコードがすべてのエクスポートクエリに含まれる [ディメンションテーブル](../../concepts/fact-and-dimension-tables.md) が含まれている場合があります。 連続エクスポートでファクトテーブルとディメンションテーブル間の結合を使用する場合は、ファクトテーブルのレコードが1回だけ処理されることに注意してください。 一部のキーに対してディメンションテーブル内のレコードが不足している間にエクスポートが実行されると、それぞれのキーのレコードが失われるか、またはエクスポートされたファイルのディメンション列に null 値が含まれます。 クエリで内部結合または外部結合が使用されているかどうかによって、失敗したレコードや null レコードが返されます。 `forcedLatency`連続エクスポート定義のプロパティは、このような場合に便利です。この場合、ファクトテーブルとディメンションテーブルが一致するレコードに対して同時に取り込まれたされます。

> [!NOTE]
> ディメンションテーブルのみの連続エクスポートはサポートされていません。 エクスポートクエリには、少なくとも1つのファクトテーブルが含まれている必要があります。

## <a name="exporting-historical-data"></a>履歴データのエクスポート

連続エクスポートでは、作成した時点からのみデータのエクスポートが開始されます。 連続していない [エクスポートコマンド](export-data-to-an-external-table.md)を使用して、その時刻より前に取り込まれたを記録します。 

履歴データが大きすぎて、1回のエクスポートコマンドでエクスポートできない可能性があります。 必要に応じて、クエリをいくつかの小さなバッチに分割します。 

連続エクスポートによってエクスポートされたデータと重複しないようにするには、[ `StartCursor` [連続エクスポートの表示] コマンド](show-continuous-export.md) によって返されたを使用し、エクスポートでは `where cursor_before_or_at` カーソル値を記録します。 次に例を示します。

```kusto
.show continuous-export MyExport | project StartCursor
```

| StartCursor        |
|--------------------|
| 636751928823156645 |

次の後に続きます。 

```kusto
.export async to table ExternalBlob
<| T | where cursor_before_or_at("636751928823156645")
```

## <a name="resource-consumption"></a>リソース消費

* 連続エクスポートがクラスターに与える影響は、連続エクスポートが実行されているクエリによって異なります。 CPU やメモリなどのほとんどのリソースは、クエリの実行によって消費されます。 
* 同時に実行できるエクスポート操作の数は、クラスターのデータエクスポート容量によって制限されます。 詳細については、「 [調整](../../management/capacitypolicy.md#throttling)」を参照してください。 クラスターにすべての連続エクスポートを処理するのに十分な容量がない場合は、遅れているが開始されます。
* [ [コマンドとクエリの表示] コマンド](../commands-and-queries.md) を使用すると、リソースの消費量を見積もることができます。 
  * [フィルター] `| where ClientActivityId startswith "RunContinuousExports"` をオンにすると、連続エクスポートに関連付けられているコマンドとクエリが表示されます。

## <a name="limitations"></a>制限事項

* 連続エクスポートは、ストリーミングインジェストを使用するデータ取り込まれたでは機能しません。 
* [行レベルセキュリティポリシー](../../management/rowlevelsecuritypolicy.md)が有効になっているテーブルで連続エクスポートを構成することはできません。
* 連続エクスポートは `impersonate` 、の [接続文字列](../../api/connection-strings/storage.md)に含まれる外部テーブルではサポートされていません。
* 連続エクスポートは、データベース間およびクラスター間の呼び出しをサポートしていません。
* 連続エクスポートは、Azure データエクスプローラーから継続的にデータをストリーミングするように設計されていません。 連続エクスポートは分散モードで実行され、すべてのノードが同時にエクスポートされます。 各実行によってクエリされるデータの範囲が小さい場合、連続エクスポートの出力は多数の小さな成果物になります。 成果物の数は、クラスター内のノードの数によって異なります。
* 連続エクスポートによって使用されるアーティファクトが Event Grid 通知をトリガーするように設計されている場合は、Event Grid のドキュメントの「 [既知の問題」セクション](../../../ingest-data-event-grid-overview.md#known-event-grid-issues)を参照してください。
